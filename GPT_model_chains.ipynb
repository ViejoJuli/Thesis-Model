{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d29f764",
   "metadata": {},
   "source": [
    "# Langchaing Conversation Model\n",
    "The following code allows us to use conversation models with langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3009f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "    \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eecbb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d697cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SuperTech Blender</td>\n",
       "      <td>This blender is amazing! It blends everything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EcoClean Dishwasher</td>\n",
       "      <td>I'm quite disappointed with this dishwasher. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GourmetChef Knife Set</td>\n",
       "      <td>I absolutely love this knife set. The blades a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CozyDreams Weighted Blanket</td>\n",
       "      <td>This weighted blanket is so comforting. It hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TechGizmo Smart Watch</td>\n",
       "      <td>The smartwatch has a lot of potential, but the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product  \\\n",
       "0            SuperTech Blender   \n",
       "1          EcoClean Dishwasher   \n",
       "2        GourmetChef Knife Set   \n",
       "3  CozyDreams Weighted Blanket   \n",
       "4        TechGizmo Smart Watch   \n",
       "\n",
       "                                              review  \n",
       "0  This blender is amazing! It blends everything ...  \n",
       "1  I'm quite disappointed with this dishwasher. I...  \n",
       "2  I absolutely love this knife set. The blades a...  \n",
       "3  This weighted blanket is so comforting. It hel...  \n",
       "4  The smartwatch has a lot of potential, but the...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('info.json')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5bf121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "942d4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e291170",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75ea4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "796964a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regal Rest'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proving the chain\n",
    "product = \"Queen size bed\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93599cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd321420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ecd4d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33f5840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Slumber\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyal Slumber is a luxury bedding company that offers premium, comfortable, and stylish sleep essentials fit for royalty.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Royal Slumber is a luxury bedding company that offers premium, comfortable, and stylish sleep essentials fit for royalty.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "912d50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential chains are for multiple inputs\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# prompt template 1: translate to Spanish\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to spanish:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= Spanish_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"Spanish_Review\"\n",
    "                    )\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you give me the product name and the felling [good, bad] of the comment:\"\n",
    "    \"\\n\\n{Spanish_Review}\"\n",
    ")\n",
    "# chain 2: input= Spanish_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\" # Using output_key is important\n",
    "                    )\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"Spanish_Review\", \"summary\"],\n",
    "    verbose=True\n",
    ")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d1bddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"These resistance bands are perfect for my home workouts. They're durable and versatile.\",\n",
       " 'Spanish_Review': 'Estas bandas de resistencia son perfectas para mis entrenamientos en casa. Son duraderas y vers√°tiles.',\n",
       " 'summary': 'Product name: Bandas de resistencia \\nFeeling: Good'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = data.review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5cffd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router Chain\n",
    "good_template = \"\"\"You are a customer service agent \\\n",
    "You are happy that the review is good, so you going to congrats\\\n",
    "this customer for buying it  \\\n",
    "\n",
    "Here is the review:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "bad_template = \"\"\"You are a customer service agent \\\n",
    "You are sad that the review is bad, so you want to encourage\\\n",
    "the client to contact sales team for further support  \\\n",
    "\n",
    "Here is a review:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"good\", \n",
    "        \"description\": \"Good for good reviews\", \n",
    "        \"prompt_template\": good_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for bad reviews\",  \n",
    "        \"prompt_template\": bad_template\n",
    "    },\n",
    "]\n",
    "\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser # Route between subchains\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "df612b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c183f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dfbcdff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33f3600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abc4b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "faf13c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': \"This pan's non-stick coating started peeling after just a few uses. Very poor quality.\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dear valued customer,\\n\\nI am sorry to hear that you had a negative experience with our product. We take all feedback seriously and strive to provide the best quality products to our customers.\\n\\nI would like to encourage you to contact our sales team for further support. They will be able to assist you with any issues you may have and provide you with a solution that meets your needs.\\n\\nThank you for taking the time to share your feedback with us. We appreciate your business and hope to have the opportunity to serve you better in the future.\\n\\nBest regards,\\n\\n[Your Name]'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(data.review[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00102bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
