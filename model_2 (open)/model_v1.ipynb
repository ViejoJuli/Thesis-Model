{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e10b60b-94a3-441b-8fe9-2bb542c78995",
   "metadata": {},
   "source": [
    "Chainlit used to create chat interface\n",
    "Link: https://docs.chainlit.io/integrations/langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288fa80-2500-46b4-9edb-97a5ec9883d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install transformers\n",
    "#!pip install langchain\n",
    "#!pip install chainlit\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1d0a59-e341-4583-8684-4ccb8b44f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import openai\n",
    "#import chainlit as cl\n",
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2415700e-ec8a-4138-b827-9dcb427e09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8a57c2-44f7-4d7c-9bc0-b376b37e7d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"gpt2-medium\" # 355M parameter\n",
    "conv_model = HuggingFaceHub(huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
    "                            repo_id=model_id,\n",
    "                            model_kwargs={\"temperature\":0.8, \"max_new_tokens\":200}) # Temperature is randomness of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4d47a7-0948-4c9f-a820-c5cb21dfbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a helpful AI assistant that makes stories by completing the query provided by the user\n",
    "\n",
    "{query}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffb1e4b-9e83-4100-98be-8b4d5349e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_chain = LLMChain(llm=conv_model,\n",
    "                      prompt=prompt,\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cd73bc-f17c-4cbb-be4d-d9690d9bc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that makes stories by completing the query provided by the user\n",
      "\n",
      "Once upon a time in 1947, a little princess\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "started to study computer programming. Over the years,\n",
      "\n",
      "she became expert in the theory and practice of\n",
      "\n",
      "programming.\n",
      "\n",
      "But one day, while in a meeting, she suddenly\n",
      "\n",
      "heard someone whispering \"Oh, a robot.\"\n",
      "\n",
      "\"Oh, yes. Yes, I can see that...\"\n",
      "\n",
      "\"Is that a robot I saw in my dream?\"\n",
      "\n",
      "\"Yes, yes it is. It is your child.\"\n",
      "\n",
      "The princess stood up and walked up the\n",
      "\n",
      "path to the exit of the building where the\n",
      "\n",
      "computer was being worked on.\n",
      "\n",
      "A robot was on the other side of the door\n",
      "\n",
      "which led to the floor of the machine room.\n",
      "\n",
      "\"Hoo hoo! It is you!\" exclaimed the computer.\n",
      "\n",
      "\"Oohh! It's you!\" exclaimed the princess.\n",
      "\n",
      "\n",
      "She walked up the main corridor to the\n",
      "\n",
      "room where she had always dreamed the robot to be.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conv_chain.run(\"Once upon a time in 1947, a little princess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3e880-8de0-4856-b010-14bfd5c870c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
