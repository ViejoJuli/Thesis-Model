{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "## Evaluation Cases\n",
    "- RAGAS: https://www.youtube.com/watch?v=Anr1br0lLz8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4811e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "llm_model = 'gpt-35-turbo-jdrios'\n",
    "emb_model = 'text-embedding-ada-002-jdrios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a80788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader([\n",
    "    \"https://www.leal.co/usuarios\",\n",
    "    \"https://www.leal.co/puntos\",\n",
    "    \"https://www.leal.co/leal-coins\"\n",
    "])\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c1e76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings (with OpenAI)\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=emb_model,\n",
    "    azure_endpoint=os.getenv('OPENAI_ENDPOINT'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1019f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings (with HuggingFace)\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "# emb_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "emb_model = \"BAAI/bge-small-en-v1.5\"\n",
    "embeddings = HuggingFaceHubEmbeddings(repo_id=emb_model,\n",
    "                                        huggingfacehub_api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb82cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Retriever\n",
    "from langchain_pinecone import Pinecone\n",
    "index_name = 'thesis-model-1'\n",
    "\n",
    "vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab66ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin Prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'Redirigir...':\n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "166e5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "primary_qa_llm = AzureChatOpenAI(model_name=llm_model, temperature=0, api_version=\"2023-09-15-preview\", azure_endpoint=os.getenv('OPENAI_ENDPOINT'))\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ee7245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tener Leal Coins es como tener efectivo, con ellos puedes adquirir lo que quieras en cualquiera de las marcas aliadas de Leal.\n"
     ]
    }
   ],
   "source": [
    "question = \"Que son los Leal coins\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d7984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Inference API\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ['HUGGINGFACEHUB_API_TOKEN']}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your\",\n",
    "})\n",
    "\n",
    "# retrieval_augmented_qa_chain = (\n",
    "#     # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "#     # \"question\" : populated by getting the value of the \"question\" key\n",
    "#     # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "#     {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "#     # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "#     #              by getting the value of the \"context\" key from the previous step\n",
    "#     | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "#     # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "#     #              into the LLM and stored in a key called \"response\"\n",
    "#     # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "#     | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97bf7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot in spanish ready to help person with their queries based on a context and chat history.\n",
      "    If the person gives you his name, please use it in all the responses. \n",
      "    QUERY: Hola, soy Julian\n",
      "    ANSWER:\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    You are a chatbot in spanish ready to help person with their queries based on a context and chat history.\\n    If the person gives you his name, please use it in all the responses. \\n    QUERY: Hola, soy Julian\\n    ANSWER:\\n    ¡Hola Julian! ¿Cómo puedo ayudarte hoy?\\n    QUERY: ¿Cómo llegar a la Plaza Mayor de Madrid?\\n    ANSWER: Para llegar a la Plaza Mayor de Madrid, puedes tomar la línea 1 del metro y bajarte en la estación de Sol. Desde allí, solo tienes que caminar durante unos minutos hasta llegar a la plaza. Otra opción es tomar la línea 3 del metro y bajarte en la estación de Santo Domingo, desde donde también es fácil llegar a la Plaza Mayor a pie. \\n    QUERY: ¿Cuánto cuesta el metro en Madrid?\\n    ANSWER: El precio del metro en Madrid es de 1,50 euros por viaje, siempre que real'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "template = \"\"\"\n",
    "    You are a chatbot in spanish ready to help person with their queries based on a context and chat history.\n",
    "    If the person gives you his name, please use it in all the responses. \n",
    "    QUERY: {query}\n",
    "    ANSWER:\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"query\"])\n",
    "llm_model2=HuggingFaceHub(repo_id='HuggingFaceH4/zephyr-7b-beta',\n",
    "                               model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 200})\n",
    "story_llm = LLMChain(llm=llm_model2,\n",
    "                         prompt=prompt,\n",
    "                         verbose=True)\n",
    "story = story_llm.predict(query=\"Hola, soy Julian\")\n",
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647bf4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Can you please let us know more details about your Camp Puzzle Collection? Are these puzzles specific to children or suitable for adults as well? Also, I am interested in knowing the types of puzzles included in this set. Would you be able to elaborate on that?\\n\\nOur Camp Puzzle Collection is a series of eight 1000-piece puzzles featuring stunning landscapes of popular campsites across the USA. These puzzles are designed to be challenging yet rewarding, making them suitable for adults as well.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Que son los Leal coins\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d51c9",
   "metadata": {},
   "source": [
    "## Evaluating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04ff5341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f41cf7bba64c4088618639aa9347c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5edef103c68480b966cb248a5416973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\executor.py\", line 79, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Julián Ríos\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 631, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\Julián Ríos\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\Julián Ríos\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\executor.py\", line 38, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\executor.py\", line 112, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\evolutions.py\", line 468, in _aevolve\n",
      "    similar_node = self.docstore.get_similar(merged_node, top_k=1)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\docstore.py\", line 342, in get_similar\n",
      "    scores, doc_ids = get_top_k_embeddings(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\docstore.py\", line 178, in get_top_k_embeddings\n",
      "    similarity = similarity_fn(query_embedding_np, emb)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\docstore.py\", line 148, in similarity\n",
      "    product = np.dot(embedding1, embedding2)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: shapes (384,) and (1536,) not aligned: 384 (dim 0) != 1536 (dim 0)\n"
     ]
    }
   ],
   "source": [
    "# Create Test Data\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(generator_llm=primary_qa_llm,critic_llm=primary_qa_llm,embeddings=embeddings)\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, \n",
    "                                                 raise_exceptions=False, with_debugging_logs=False,\n",
    "                                                 distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e18f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are Leal Coins and how can they be used?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins are a universal currency that can b...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What kind of rewards can be redeemed with Leal...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The answer to given question is present in con...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Leal and how does it help users earn r...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal is an app that allows users to earn rewar...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Leal and how does it help users earn r...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal is an app that allows users to earn rewar...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are Leal Coins and how can they be used?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins are a universal currency that can b...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the rewards and differences between L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The points earned through purchases on Leal ca...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the rewards and differences between L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The points earned through purchases on Leal ca...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the uses and ways to earn Leal Coins?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins can be earned through various ways ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the process for earning rewards with L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>nan</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      What are Leal Coins and how can they be used?   \n",
       "1  What kind of rewards can be redeemed with Leal...   \n",
       "2  What is Leal and how does it help users earn r...   \n",
       "3  What is Leal and how does it help users earn r...   \n",
       "4      What are Leal Coins and how can they be used?   \n",
       "5  What are the rewards and differences between L...   \n",
       "6  What are the rewards and differences between L...   \n",
       "7     What are the uses and ways to earn Leal Coins?   \n",
       "8  What is the process for earning rewards with L...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "1  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "2  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "3  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "4  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "5  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "6  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "7  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "8  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Leal Coins are a universal currency that can b...         simple   \n",
       "1  The answer to given question is present in con...         simple   \n",
       "2  Leal is an app that allows users to earn rewar...         simple   \n",
       "3  Leal is an app that allows users to earn rewar...         simple   \n",
       "4  Leal Coins are a universal currency that can b...         simple   \n",
       "5  The points earned through purchases on Leal ca...      reasoning   \n",
       "6  The points earned through purchases on Leal ca...      reasoning   \n",
       "7  Leal Coins can be earned through various ways ...  multi_context   \n",
       "8                                                nan  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "1  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "2  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "3  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "4  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "5  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "6  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "7  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "8  [{'source': 'https://www.leal.co/usuarios', 't...          True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5896af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0347373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add answers to the dataframe\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "338ad0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "074bdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed variables\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0aa2de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f79e2304c04c32af19eb3e8b7a7e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Select Embeddings Model\n",
    "results = evaluate(response_dataset, metrics, llm=primary_qa_llm,embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "388e1a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8889, 'answer_relevancy': 0.8628, 'context_recall': 0.7778, 'context_precision': 0.7593, 'answer_correctness': 0.5882}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "164c0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you do with the points you accumulate...</td>\n",
       "      <td>You can redeem the points for exclusive prizes...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>You can redeem the points you accumulate in th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can you do with the points you accumulate...</td>\n",
       "      <td>You can redeem the points for exclusive prizes...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>You can redeem the points you accumulate in th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What distinguishes points from Leal Coins in t...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.926413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What distinguishes points from Leal Coins in t...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.926413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What's the difference between Puntos and Leal ...</td>\n",
       "      <td>The points can be redeemed for exclusive rewar...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Puntos can be redeemed for exclusive rewards f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.575817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What's the difference between Puntos and Leal ...</td>\n",
       "      <td>The points can be redeemed for exclusive rewar...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Puntos can be redeemed for exclusive rewards f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.575817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What can you do with the points you accumulate...   \n",
       "1   What can you use Leal Coins for in the Leal app?   \n",
       "2  What can you do with the points you accumulate...   \n",
       "3   What can you use Leal Coins for in the Leal app?   \n",
       "4   What can you use Leal Coins for in the Leal app?   \n",
       "5  What distinguishes points from Leal Coins in t...   \n",
       "6  What distinguishes points from Leal Coins in t...   \n",
       "7  What's the difference between Puntos and Leal ...   \n",
       "8  What's the difference between Puntos and Leal ...   \n",
       "9   What can you use Leal Coins for in the Leal app?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  You can redeem the points for exclusive prizes...   \n",
       "1  You can use Leal Coins in thousands of physica...   \n",
       "2  You can redeem the points for exclusive prizes...   \n",
       "3  You can use Leal Coins in thousands of physica...   \n",
       "4  You can use Leal Coins in thousands of physica...   \n",
       "5  Points can be redeemed for exclusive rewards i...   \n",
       "6  Points can be redeemed for exclusive rewards i...   \n",
       "7  The points can be redeemed for exclusive rewar...   \n",
       "8  The points can be redeemed for exclusive rewar...   \n",
       "9  You can use Leal Coins in thousands of physica...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "1  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "2  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "3  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "4  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "5  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "6  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "7  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "8  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "9  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  You can redeem the points you accumulate in th...      1.000000   \n",
       "1  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "2  You can redeem the points you accumulate in th...      1.000000   \n",
       "3  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "4  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "5  Points can be redeemed for exclusive rewards i...      0.666667   \n",
       "6  Points can be redeemed for exclusive rewards i...      0.666667   \n",
       "7  Puntos can be redeemed for exclusive rewards f...      1.000000   \n",
       "8  Puntos can be redeemed for exclusive rewards f...      1.000000   \n",
       "9  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0          0.865079        1.000000           1.000000            0.731761  \n",
       "1          0.954475        1.000000           1.000000            0.899607  \n",
       "2          0.865079        1.000000           1.000000            0.731761  \n",
       "3          0.954475        1.000000           1.000000            0.899607  \n",
       "4          0.954475        1.000000           1.000000            0.899607  \n",
       "5          0.926413        1.000000           1.000000            0.581555  \n",
       "6          0.926413        1.000000           1.000000            0.581555  \n",
       "7          0.000000        1.000000           0.805556            0.575817  \n",
       "8          0.000000        0.666667           0.805556            0.575817  \n",
       "9          0.954475        1.000000           1.000000            0.899607  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results.to_pandas()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed93cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [04:40<00:00,  5.61s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291132f8",
   "metadata": {},
   "source": [
    "## Better implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "147b34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "retrieval_qa_prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57cfbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_qa_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9054a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query Retriever\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)\n",
    "\n",
    "# Document \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(primary_qa_llm, prompt)\n",
    "\n",
    "# Retrieval Chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9e2fa1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'question'}.  Expected: ['context', 'question'] Received: ['input', 'context']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQue son los Leal Coins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4458\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4454\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4455\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2446\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2446\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2450\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:454\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    451\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:441\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    434\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[0;32m    437\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m--> 441\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    446\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   3078\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3079\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3080\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   3081\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3089\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3090\u001b[0m         ]\n\u001b[1;32m-> 3091\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3092\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3093\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4458\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4454\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4455\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2446\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2446\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2450\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\prompts\\base.py:118\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    117\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\prompts\\base.py:103\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    101\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'question'}.  Expected: ['context', 'question'] Received: ['input', 'context']\""
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Que son los Leal Coins\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b4745b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m     current_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mchatbot_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm having trouble logging in.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 62\u001b[0m, in \u001b[0;36mchatbot_response\u001b[1;34m(user_query, chatbot_name, company_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompts[current_prompt]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m user_query:\n\u001b[1;32m---> 62\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRESPONSE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchar\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mABC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRESPONSE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchar\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:347\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def chatbot_response(user_query, chatbot_name=\"Le A.I\", company_name=\"Leal\"):\n",
    "  \"\"\"\n",
    "  This function simulates a friendly customer service chatbot conversation.\n",
    "\n",
    "  Args:\n",
    "      user_query: The user's question or input.\n",
    "      chatbot_name: The name of the chatbot\n",
    "      company_name: The name of your company\n",
    "\n",
    "  Returns:\n",
    "      A string representing the chatbot's response.\n",
    "  \"\"\"\n",
    "  # Define conversation flow\n",
    "  prompts = [\n",
    "      {\n",
    "          \"START_SEQ\": True,\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": f\"Hi there! I'm {chatbot_name}, your friendly customer service assistant for {company_name}. How can I help you today?\",\n",
    "          \"RESPONSE B\": f\"Great to see you! Is there anything I can assist you with on this day?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": f\"I understand you're having trouble with {user_query}. Let's see what we can do to fix that.\",\n",
    "          \"RESPONSE B\": f\"It sounds like you're looking for information about {user_query}. I'm happy to help you find what you need.\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"Here are a few things you can try: [List your solutions here]. Let me know if any of these work!\",\n",
    "          \"RESPONSE B\": f\"I can definitely walk you through the steps for {user_query}. Would you like me to do that?\",\n",
    "          \"RESPONSE C\": f\"No problem! I've found some helpful resources on {user_query} that you might find useful: [List your resources here].\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"No worries at all! We'll get this figured out together.\",\n",
    "          \"RESPONSE B\": \"That's a great question! Let me see if I can find an answer for you.\",\n",
    "          \"RESPONSE C\": f\"I apologize for any inconvenience this may have caused. Is there anything else I can do to assist you today?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"If the issue seems complex, you can offer to connect the user to a human agent.\",\n",
    "          \"RESPONSE B\": f\"It seems like your situation might require a bit more personalized attention. Would you like me to connect you with one of our customer service representatives?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"I hope this information was helpful! Is there anything else I can help you with today?\",\n",
    "          \"RESPONSE B\": \"Glad I could be of assistance! Have a wonderful {day.name}!\"\n",
    "      },\n",
    "      {\n",
    "          \"END_SEQ\": True,\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": None,\n",
    "          \"RESPONSE B\": None\n",
    "      }\n",
    "  ]\n",
    "\n",
    "  # Loop through conversation prompts\n",
    "  current_prompt = 0\n",
    "  while current_prompt < len(prompts):\n",
    "    prompt = prompts[current_prompt]\n",
    "    if prompt.get(\"USER_QUERY\") is None or prompt.get(\"USER_QUERY\") == user_query:\n",
    "      response = random.choice([prompt.get(f\"RESPONSE {char}\") for char in \"ABC\" if prompt.get(f\"RESPONSE {char}\")==\"\"])\n",
    "      if response:\n",
    "        print(response)\n",
    "      if prompt.get(\"END_SEQ\"):\n",
    "        break\n",
    "    current_prompt += 1\n",
    "\n",
    "# Example usage\n",
    "chatbot_response(\"I'm having trouble logging in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d695e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e30b302d00485994b4a67ba7f8d345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Julián Ríos\\.cache\\huggingface\\hub\\models--pysentimiento--robertuito-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c8dea4a54c44aeaba49c3f30285685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397a7f78c3bf4a3184f3fb0635835dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03f5b61c67d44629ebea67033c314a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ca73a1fa3d42a8adf66246b699136f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.946, NEU: 0.037, NEG: 0.017})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "analyzer.predict(\"Qué gran jugador es Messi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a22329",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable AnalyzerOutput object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentiment, probas \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQué gran jugador es Messi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable AnalyzerOutput object"
     ]
    }
   ],
   "source": [
    "sentiment, probas = analyzer.predict(\"Qué gran jugador es Messi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "625c4f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POS'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25379993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
