{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "## Evaluation Cases\n",
    "- RAGAS: https://www.youtube.com/watch?v=Anr1br0lLz8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4811e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "llm_model = 'gpt-35-turbo-jdrios'\n",
    "emb_model = 'text-embedding-ada-002-jdrios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader([\n",
    "    \"https://www.leal.co/usuarios\",\n",
    "    \"https://www.leal.co/puntos\",\n",
    "    \"https://www.leal.co/leal-coins\"\n",
    "])\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1e76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings (with OpenAI)\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=emb_model,\n",
    "    azure_endpoint=os.getenv('OPENAI_ENDPOINT'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1019f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings (with HuggingFace)\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "# emb_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "emb_model = \"BAAI/bge-small-en-v1.5\"\n",
    "embeddings = HuggingFaceHubEmbeddings(repo_id=emb_model,\n",
    "                                        huggingfacehub_api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb82cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Retriever\n",
    "from langchain_pinecone import Pinecone\n",
    "index_name = 'thesis-model-1'\n",
    "\n",
    "vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab66ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin Prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'Redirigir...':\n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166e5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "primary_qa_llm = AzureChatOpenAI(model_name=llm_model, temperature=0, api_version=\"2023-09-15-preview\", azure_endpoint=os.getenv('OPENAI_ENDPOINT'))\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ee7245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tener Leal Coins es como tener efectivo, con ellos puedes adquirir lo que quieras en cualquiera de las marcas aliadas de Leal.\n"
     ]
    }
   ],
   "source": [
    "question = \"Que son los Leal coins\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207784e1",
   "metadata": {},
   "source": [
    "# HF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b8ac622",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.llms.huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInferenceAPI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInferenceAPIEmbedding\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.llms.huggingface'"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceInferenceAPIEmbedding\n",
    "import pandas as pd\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def build_query_engine(llm):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=ServiceContext.from_defaults(chunk_size=512, llm=llm),\n",
    "        embed_model=HuggingFaceInferenceAPIEmbedding,\n",
    "    )\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "    return query_engine\n",
    "\n",
    "# Function to evaluate as Llama index does not support async evaluation for HFInference API\n",
    "def generate_responses(query_engine, test_questions, test_answers):\n",
    "  responses = [query_engine.query(q) for q in test_questions]\n",
    "\n",
    "  answers = []\n",
    "  contexts = []\n",
    "  for r in responses:\n",
    "    answers.append(r.response)\n",
    "    contexts.append([c.node.get_content() for c in r.source_nodes])\n",
    "  dataset_dict = {\n",
    "        \"question\": test_questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "  }\n",
    "  if test_answers is not None:\n",
    "    dataset_dict[\"ground_truth\"] = test_answers\n",
    "  ds = Dataset.from_dict(dataset_dict)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d7984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'Redirigir...':\n",
      "Context:\n",
      "[Document(page_content='Los Leal Coins, son como el efectivo', metadata={'description': 'Encuentra en la app Leal una forma fácil de disfrutar lo que más te gusta.', 'language': 'No language found.', 'source': 'https://www.leal.co/leal-coins', 'title': 'Los Leal Coins, son como el efectivo'}), Document(page_content='Usuarios Leal, puntos y Leal Coins', metadata={'description': 'Los puntos puedes redimirlos por premios exclusivos en la marca en la que acumulas, los Leal Coins son universales y puedes usarlos en miles de marcas físicas u online que tenemos para ti.', 'language': 'No language found.', 'source': 'https://www.leal.co/usuarios', 'title': 'Usuarios Leal, puntos y Leal Coins'}), Document(page_content='Tus puntos se convierten en premios', metadata={'description': 'Tenemos cientos de comercios donde ganas premios por hacer lo de siempre: disfrutar en tus marcas favoritas.', 'language': 'No language found.', 'source': 'https://www.leal.co/puntos', 'title': 'Tus puntos se convierten en premios'}), Document(page_content='InicioUsuariosComerciosNosotrosResource Link 1Resource Link 2Resource Link 3Descarga la app¡Conoce el poder de losLeal Coins!Encuentra en la app Leal una forma fácil de disfrutarlo que más te gusta.¿Qué son losLeal Coins?Tener Leal Coins es como tener efectivo, con ellos puedes adquirir lo que quieras en cualquiera de nuestras marcas aliadas.¿Cómo ganarlos?CompraOnlineTe devolvemos hasta el 17% de las compras que realices desde nuestra app Leal.Conoce más >Ofertas exclusivasEncuentra en la app Leal ofertas únicas con marcas que te dan mucho Cashback por tus compras.Conoce más >Tarjeta de créditoGana hasta el 5% de Cashback en todas tus compras y acumula puntos en nuestras marcas', metadata={'description': 'Encuentra en la app Leal una forma fácil de disfrutar lo que más te gusta.', 'language': 'No language found.', 'source': 'https://www.leal.co/leal-coins', 'title': 'Los Leal Coins, son como el efectivo'})]\n",
      "Question:\n",
      "Hola, soy Julian\n",
      "\n",
      "¿Cómo puedo obtener Leal Coins y qué puedo hacer con ellos?\n",
      "\n",
      "Respuesta:\n",
      "Hola Julian,\n",
      "\n",
      "Para obtener Leal Coins, puedes realizar diferentes acciones en nuestra app Leal. Por ejemplo, compras en línea te devolverán hasta el 17% de las compras que realices desde nuestra app Leal. Además, puedes encontrar ofert\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "primary_qa_llm=HuggingFaceHub(repo_id='HuggingFaceH4/zephyr-7b-beta', # 'tiiuae/falcon-7b-instruct',\n",
    "                               model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 100})\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "question = \"Hola, soy Julian\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Que son los Leal coins\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d51c9",
   "metadata": {},
   "source": [
    "## Evaluating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ff5341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bede526f0ac4f929d84e0dab25559c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtestset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevolutions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple, reasoning, multi_context\n\u001b[0;32m      6\u001b[0m generator \u001b[38;5;241m=\u001b[39m TestsetGenerator\u001b[38;5;241m.\u001b[39mfrom_langchain(generator_llm\u001b[38;5;241m=\u001b[39mprimary_qa_llm,critic_llm\u001b[38;5;241m=\u001b[39mprimary_qa_llm,embeddings\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[1;32m----> 7\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43msimple\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_context\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\generator.py:179\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[1;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(\n\u001b[0;32m    176\u001b[0m     [Document\u001b[38;5;241m.\u001b[39mfrom_langchain_document(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    177\u001b[0m )\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_async\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\generator.py:248\u001b[0m, in \u001b[0;36mTestsetGenerator.generate\u001b[1;34m(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[0;32m    237\u001b[0m     patch_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mragas.llms.prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, logging\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[0;32m    239\u001b[0m exec \u001b[38;5;241m=\u001b[39m Executor(\n\u001b[0;32m    240\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    241\u001b[0m     keep_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    242\u001b[0m     raise_exceptions\u001b[38;5;241m=\u001b[39mraise_exceptions,\n\u001b[0;32m    243\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m current_nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    247\u001b[0m     CurrentNodes(root_node\u001b[38;5;241m=\u001b[39mn, nodes\u001b[38;5;241m=\u001b[39m[n])\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m ]\n\u001b[0;32m    250\u001b[0m total_evolutions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evolution, probability \u001b[38;5;129;01min\u001b[39;00m distributions\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\ragas\\testset\\docstore.py:328\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.get_random_nodes\u001b[1;34m(self, k, alpha)\u001b[0m\n\u001b[0;32m    325\u001b[0m prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(similarity_scores)\n\u001b[0;32m    326\u001b[0m prob \u001b[38;5;241m=\u001b[39m prob \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(prob)\n\u001b[1;32m--> 328\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    331\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mindex(node)\n",
      "File \u001b[1;32mnumpy\\\\random\\\\_generator.pyx:803\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Create Test Data\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(generator_llm=primary_qa_llm,critic_llm=primary_qa_llm,embeddings=embeddings)\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=30, \n",
    "                                                 raise_exceptions=False, with_debugging_logs=False,\n",
    "                                                 distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are Leal Coins and how can they be used?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins are a universal currency that can b...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What kind of rewards can be redeemed with Leal...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The answer to given question is present in con...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Leal and how does it help users earn r...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal is an app that allows users to earn rewar...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Leal and how does it help users earn r...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal is an app that allows users to earn rewar...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are Leal Coins and how can they be used?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins are a universal currency that can b...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the rewards and differences between L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The points earned through purchases on Leal ca...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the rewards and differences between L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>The points earned through purchases on Leal ca...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the uses and ways to earn Leal Coins?</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>Leal Coins can be earned through various ways ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the process for earning rewards with L...</td>\n",
       "      <td>[Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...</td>\n",
       "      <td>nan</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'https://www.leal.co/usuarios', 't...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      What are Leal Coins and how can they be used?   \n",
       "1  What kind of rewards can be redeemed with Leal...   \n",
       "2  What is Leal and how does it help users earn r...   \n",
       "3  What is Leal and how does it help users earn r...   \n",
       "4      What are Leal Coins and how can they be used?   \n",
       "5  What are the rewards and differences between L...   \n",
       "6  What are the rewards and differences between L...   \n",
       "7     What are the uses and ways to earn Leal Coins?   \n",
       "8  What is the process for earning rewards with L...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "1  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "2  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "3  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "4  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "5  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "6  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "7  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "8  [Usuarios Leal, puntos y Leal Coins\\n\\n\\n\\n\\nI...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Leal Coins are a universal currency that can b...         simple   \n",
       "1  The answer to given question is present in con...         simple   \n",
       "2  Leal is an app that allows users to earn rewar...         simple   \n",
       "3  Leal is an app that allows users to earn rewar...         simple   \n",
       "4  Leal Coins are a universal currency that can b...         simple   \n",
       "5  The points earned through purchases on Leal ca...      reasoning   \n",
       "6  The points earned through purchases on Leal ca...      reasoning   \n",
       "7  Leal Coins can be earned through various ways ...  multi_context   \n",
       "8                                                nan  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "1  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "2  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "3  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "4  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "5  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "6  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "7  [{'source': 'https://www.leal.co/usuarios', 't...          True  \n",
       "8  [{'source': 'https://www.leal.co/usuarios', 't...          True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5896af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0347373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add answers to the dataframe\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "338ad0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "074bdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed variables\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0aa2de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f79e2304c04c32af19eb3e8b7a7e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Select Embeddings Model\n",
    "results = evaluate(response_dataset, metrics, llm=primary_qa_llm,embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "388e1a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8889, 'answer_relevancy': 0.8628, 'context_recall': 0.7778, 'context_precision': 0.7593, 'answer_correctness': 0.5882}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "164c0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you do with the points you accumulate...</td>\n",
       "      <td>You can redeem the points for exclusive prizes...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>You can redeem the points you accumulate in th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can you do with the points you accumulate...</td>\n",
       "      <td>You can redeem the points for exclusive prizes...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>You can redeem the points you accumulate in th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What distinguishes points from Leal Coins in t...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.926413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What distinguishes points from Leal Coins in t...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Points can be redeemed for exclusive rewards i...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.926413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What's the difference between Puntos and Leal ...</td>\n",
       "      <td>The points can be redeemed for exclusive rewar...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Puntos can be redeemed for exclusive rewards f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.575817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What's the difference between Puntos and Leal ...</td>\n",
       "      <td>The points can be redeemed for exclusive rewar...</td>\n",
       "      <td>[tu app Leal y entérate cuantos puntos te falt...</td>\n",
       "      <td>Puntos can be redeemed for exclusive rewards f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.575817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What can you use Leal Coins for in the Leal app?</td>\n",
       "      <td>You can use Leal Coins in thousands of physica...</td>\n",
       "      <td>[crédito Leal y gana cashback hasta de 5% con ...</td>\n",
       "      <td>Leal Coins can be used to acquire bonuses from...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What can you do with the points you accumulate...   \n",
       "1   What can you use Leal Coins for in the Leal app?   \n",
       "2  What can you do with the points you accumulate...   \n",
       "3   What can you use Leal Coins for in the Leal app?   \n",
       "4   What can you use Leal Coins for in the Leal app?   \n",
       "5  What distinguishes points from Leal Coins in t...   \n",
       "6  What distinguishes points from Leal Coins in t...   \n",
       "7  What's the difference between Puntos and Leal ...   \n",
       "8  What's the difference between Puntos and Leal ...   \n",
       "9   What can you use Leal Coins for in the Leal app?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  You can redeem the points for exclusive prizes...   \n",
       "1  You can use Leal Coins in thousands of physica...   \n",
       "2  You can redeem the points for exclusive prizes...   \n",
       "3  You can use Leal Coins in thousands of physica...   \n",
       "4  You can use Leal Coins in thousands of physica...   \n",
       "5  Points can be redeemed for exclusive rewards i...   \n",
       "6  Points can be redeemed for exclusive rewards i...   \n",
       "7  The points can be redeemed for exclusive rewar...   \n",
       "8  The points can be redeemed for exclusive rewar...   \n",
       "9  You can use Leal Coins in thousands of physica...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "1  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "2  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "3  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "4  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "5  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "6  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "7  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "8  [tu app Leal y entérate cuantos puntos te falt...   \n",
       "9  [crédito Leal y gana cashback hasta de 5% con ...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  You can redeem the points you accumulate in th...      1.000000   \n",
       "1  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "2  You can redeem the points you accumulate in th...      1.000000   \n",
       "3  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "4  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "5  Points can be redeemed for exclusive rewards i...      0.666667   \n",
       "6  Points can be redeemed for exclusive rewards i...      0.666667   \n",
       "7  Puntos can be redeemed for exclusive rewards f...      1.000000   \n",
       "8  Puntos can be redeemed for exclusive rewards f...      1.000000   \n",
       "9  Leal Coins can be used to acquire bonuses from...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0          0.865079        1.000000           1.000000            0.731761  \n",
       "1          0.954475        1.000000           1.000000            0.899607  \n",
       "2          0.865079        1.000000           1.000000            0.731761  \n",
       "3          0.954475        1.000000           1.000000            0.899607  \n",
       "4          0.954475        1.000000           1.000000            0.899607  \n",
       "5          0.926413        1.000000           1.000000            0.581555  \n",
       "6          0.926413        1.000000           1.000000            0.581555  \n",
       "7          0.000000        1.000000           0.805556            0.575817  \n",
       "8          0.000000        0.666667           0.805556            0.575817  \n",
       "9          0.954475        1.000000           1.000000            0.899607  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results.to_pandas()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed93cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [04:40<00:00,  5.61s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291132f8",
   "metadata": {},
   "source": [
    "## Better implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "147b34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "retrieval_qa_prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57cfbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_qa_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9054a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query Retriever\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)\n",
    "\n",
    "# Document \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(primary_qa_llm, prompt)\n",
    "\n",
    "# Retrieval Chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9e2fa1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'question'}.  Expected: ['context', 'question'] Received: ['input', 'context']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQue son los Leal Coins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4458\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4454\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4455\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2446\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2446\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2450\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:454\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    451\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:441\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    434\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[0;32m    437\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m--> 441\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    446\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   3078\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3079\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3080\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   3081\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3089\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3090\u001b[0m         ]\n\u001b[1;32m-> 3091\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3092\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3093\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4458\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4454\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4455\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2446\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2446\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2450\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\prompts\\base.py:118\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    117\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\langchain_core\\prompts\\base.py:103\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    101\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'question'}.  Expected: ['context', 'question'] Received: ['input', 'context']\""
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Que son los Leal Coins\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b4745b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m     current_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mchatbot_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm having trouble logging in.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 62\u001b[0m, in \u001b[0;36mchatbot_response\u001b[1;34m(user_query, chatbot_name, company_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompts[current_prompt]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m user_query:\n\u001b[1;32m---> 62\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRESPONSE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchar\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mABC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRESPONSE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchar\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:347\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def chatbot_response(user_query, chatbot_name=\"Le A.I\", company_name=\"Leal\"):\n",
    "  \"\"\"\n",
    "  This function simulates a friendly customer service chatbot conversation.\n",
    "\n",
    "  Args:\n",
    "      user_query: The user's question or input.\n",
    "      chatbot_name: The name of the chatbot\n",
    "      company_name: The name of your company\n",
    "\n",
    "  Returns:\n",
    "      A string representing the chatbot's response.\n",
    "  \"\"\"\n",
    "  # Define conversation flow\n",
    "  prompts = [\n",
    "      {\n",
    "          \"START_SEQ\": True,\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": f\"Hi there! I'm {chatbot_name}, your friendly customer service assistant for {company_name}. How can I help you today?\",\n",
    "          \"RESPONSE B\": f\"Great to see you! Is there anything I can assist you with on this day?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": f\"I understand you're having trouble with {user_query}. Let's see what we can do to fix that.\",\n",
    "          \"RESPONSE B\": f\"It sounds like you're looking for information about {user_query}. I'm happy to help you find what you need.\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"Here are a few things you can try: [List your solutions here]. Let me know if any of these work!\",\n",
    "          \"RESPONSE B\": f\"I can definitely walk you through the steps for {user_query}. Would you like me to do that?\",\n",
    "          \"RESPONSE C\": f\"No problem! I've found some helpful resources on {user_query} that you might find useful: [List your resources here].\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"No worries at all! We'll get this figured out together.\",\n",
    "          \"RESPONSE B\": \"That's a great question! Let me see if I can find an answer for you.\",\n",
    "          \"RESPONSE C\": f\"I apologize for any inconvenience this may have caused. Is there anything else I can do to assist you today?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"If the issue seems complex, you can offer to connect the user to a human agent.\",\n",
    "          \"RESPONSE B\": f\"It seems like your situation might require a bit more personalized attention. Would you like me to connect you with one of our customer service representatives?\"\n",
    "      },\n",
    "      {\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": \"I hope this information was helpful! Is there anything else I can help you with today?\",\n",
    "          \"RESPONSE B\": \"Glad I could be of assistance! Have a wonderful {day.name}!\"\n",
    "      },\n",
    "      {\n",
    "          \"END_SEQ\": True,\n",
    "          \"USER_QUERY\": None,\n",
    "          \"RESPONSE A\": None,\n",
    "          \"RESPONSE B\": None\n",
    "      }\n",
    "  ]\n",
    "\n",
    "  # Loop through conversation prompts\n",
    "  current_prompt = 0\n",
    "  while current_prompt < len(prompts):\n",
    "    prompt = prompts[current_prompt]\n",
    "    if prompt.get(\"USER_QUERY\") is None or prompt.get(\"USER_QUERY\") == user_query:\n",
    "      response = random.choice([prompt.get(f\"RESPONSE {char}\") for char in \"ABC\" if prompt.get(f\"RESPONSE {char}\")==\"\"])\n",
    "      if response:\n",
    "        print(response)\n",
    "      if prompt.get(\"END_SEQ\"):\n",
    "        break\n",
    "    current_prompt += 1\n",
    "\n",
    "# Example usage\n",
    "chatbot_response(\"I'm having trouble logging in.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d695e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e30b302d00485994b4a67ba7f8d345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Julián Ríos\\.cache\\huggingface\\hub\\models--pysentimiento--robertuito-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c8dea4a54c44aeaba49c3f30285685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397a7f78c3bf4a3184f3fb0635835dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03f5b61c67d44629ebea67033c314a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ca73a1fa3d42a8adf66246b699136f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Julián Ríos\\Desktop\\Repository\\Machine Learning\\Thesis Model\\.venv_thesis\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.946, NEU: 0.037, NEG: 0.017})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "analyzer.predict(\"Qué gran jugador es Messi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a22329",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable AnalyzerOutput object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentiment, probas \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQué gran jugador es Messi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable AnalyzerOutput object"
     ]
    }
   ],
   "source": [
    "sentiment, probas = analyzer.predict(\"Qué gran jugador es Messi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "625c4f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POS'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25379993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
