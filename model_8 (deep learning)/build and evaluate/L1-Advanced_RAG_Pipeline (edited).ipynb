{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3123d3d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Load dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Parameters\n",
    "azure_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "api_version = \"2023-09-15-preview\"\n",
    "llm_model = 'gpt-35-turbo-jdrios'\n",
    "emb_model = 'text-embedding-ada-002-jdrios'\n",
    "\n",
    "# Models\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=llm_model,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=emb_model,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2baff-5e8b-4733-9899-16f248777b23",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=embed_model\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document], \n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Query Engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"How are you? My name is Julian\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1ac5",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead7dc1-71b2-4001-918f-bf8d610fd3fd",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a278f8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5204e8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd20b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trulens-eval==0.26.0\n",
      "  Using cached trulens_eval-0.26.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (1.26.1)\n",
      "Collecting frozendict>=2.3.8 (from trulens-eval==0.26.0)\n",
      "  Using cached frozendict-2.4.0-cp39-cp39-win_amd64.whl.metadata (23 kB)\n",
      "Collecting munch>=3.0.0 (from trulens-eval==0.26.0)\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dill>=0.3.7 (from trulens-eval==0.26.0)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in c:\\users\\julián ríos\\appdata\\roaming\\python\\python39\\site-packages (from trulens-eval==0.26.0) (4.66.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\julián ríos\\appdata\\roaming\\python\\python39\\site-packages (from trulens-eval==0.26.0) (2.31.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.8 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (1.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (4.10.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (2.6.4)\n",
      "Collecting merkle-json>=1.0.0 (from trulens-eval==0.26.0)\n",
      "  Using cached merkle_json-1.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: langchain>=0.0.354 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (0.1.12)\n",
      "Requirement already satisfied: langchain-core>=0.1.6 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (0.1.32)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\anaconda3\\lib\\site-packages (from trulens-eval==0.26.0) (0.9.0)\n",
      "Collecting millify>=0.1.1 (from trulens-eval==0.26.0)\n",
      "  Using cached millify-0.1.1.tar.gz (1.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting humanize>=4.6.0 (from trulens-eval==0.26.0)\n",
      "  Using cached humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "INFO: pip is looking at multiple versions of trulens-eval to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ltk (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5; 1.12.1 Requires-Python >=3.7, !=3.9.7; 1.12.1rc1 Requires-Python >=3.7, !=3.9.7; 1.12.2 Requires-Python >=3.7, !=3.9.7; 1.12.2rc1 Requires-Python >=3.7, !=3.9.7; 1.12.2rc2 Requires-Python >=3.7, !=3.9.7; 1.13.0 Requires-Python >=3.7, !=3.9.7; 1.13.0rc1 Requires-Python >=3.7, !=3.9.7; 1.13.0rc2 Requires-Python >=3.7, !=3.9.7; 1.14.0 Requires-Python >=3.7, !=3.9.7; 1.14.0rc1 Requires-Python >=3.7, !=3.9.7; 1.14.1 Requires-Python >=3.7, !=3.9.7; 1.14.1rc1 Requires-Python >=3.7, !=3.9.7; 1.15.0 Requires-Python >=3.7, !=3.9.7; 1.15.1 Requires-Python >=3.7, !=3.9.7; 1.15.2 Requires-Python >=3.7, !=3.9.7; 1.15.2rc1 Requires-Python >=3.7, !=3.9.7; 1.16.0 Requires-Python >=3.7, !=3.9.7; 1.17.0 Requires-Python >=3.7, !=3.9.7; 1.18.0 Requires-Python >=3.7, !=3.9.7; 1.18.1 Requires-Python >=3.7, !=3.9.7; 1.18.1rc1 Requires-Python >=3.7, !=3.9.7; 1.19.0 Requires-Python >=3.7, !=3.9.7; 1.20.0 Requires-Python >=3.7, !=3.9.7; 1.21.0 Requires-Python >=3.7, !=3.9.7; 1.22.0 Requires-Python >=3.7, !=3.9.7; 1.23.0 Requires-Python >=3.7, !=3.9.7; 1.23.1 Requires-Python >=3.7, !=3.9.7; 1.24.0 Requires-Python >=3.8, !=3.9.7; 1.24.1 Requires-Python >=3.8, !=3.9.7; 1.25.0 Requires-Python >=3.8, !=3.9.7; 1.26.0 Requires-Python >=3.8, !=3.9.7; 1.27.0 Requires-Python >=3.8, !=3.9.7; 1.27.1 Requires-Python >=3.8, !=3.9.7; 1.27.2 Requires-Python >=3.8, !=3.9.7; 1.28.0 Requires-Python >=3.8, !=3.9.7; 1.28.1 Requires-Python >=3.8, !=3.9.7; 1.28.2 Requires-Python >=3.8, !=3.9.7; 1.29.0 Requires-Python >=3.8, !=3.9.7; 1.30.0 Requires-Python >=3.8, !=3.9.7; 1.31.0 Requires-Python >=3.8, !=3.9.7; 1.31.1 Requires-Python >=3.8, !=3.9.7; 1.32.0 Requires-Python >=3.8, !=3.9.7; 1.32.1 Requires-Python >=3.8, !=3.9.7; 1.32.2 Requires-Python >=3.8, !=3.9.7; 1.32.2rc1 Requires-Python >=3.8, !=3.9.7\n",
      "ERROR: Could not find a version that satisfies the requirement streamlit>=1.31.1 (from trulens-eval) (from versions: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.8.2, 0.9.0, 0.11.0, 0.12.2, 0.12.3, 0.12.4, 0.13.0, 0.13.1, 0.13.3, 0.13.5, 0.14.2, 0.15.0, 0.15.1, 0.15.2, 0.15.3, 0.15.4, 0.15.5, 0.15.6, 0.16.0, 0.16.1, 0.16.2, 0.16.3, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.22.2, 0.23.0, 0.24.0, 0.24.1, 0.24.2, 0.24.3, 0.25.0, 0.26.0, 0.26.1, 0.27.0, 0.28.0, 0.29.0, 0.30.0, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.0, 0.37.0, 0.40.0, 0.40.1, 0.41.0, 0.42.0, 0.43.0, 0.43.1, 0.43.2, 0.44.0, 0.45.0, 0.46.0, 0.47.0, 0.47.1, 0.47.2, 0.47.3, 0.47.4, 0.48.0, 0.48.1, 0.49.0, 0.50.0, 0.50.1, 0.50.2, 0.51.0, 0.52.0, 0.52.1, 0.52.2, 0.53.0, 0.54.0, 0.55.0, 0.56.0, 0.57.0, 0.57.1, 0.57.2, 0.57.3, 0.58.0, 0.59.0, 0.60.0, 0.61.0, 0.62.0, 0.62.1, 0.63.0, 0.63.1, 0.64.0, 0.65.0, 0.65.1, 0.65.2, 0.66.0, 0.67.0, 0.67.1, 0.68.0, 0.68.1, 0.69.0, 0.69.1, 0.69.2, 0.70.0, 0.71.0, 0.72.0, 0.73.0, 0.73.1, 0.74.0, 0.74.1, 0.75.0, 0.76.0, 0.77.0, 0.78.0, 0.79.0, 0.80.0, 0.81.0, 0.81.1, 0.82.0, 0.83.0, 0.84.0, 0.84.1, 0.84.2, 0.85.0, 0.85.1, 0.86.0, 0.87.0, 0.88.0, 0.89.0, 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0rc3, 1.6.0rc4, 1.6.0, 1.7.0, 1.8.0rc1, 1.8.0, 1.8.1rc1, 1.8.1, 1.9.0rc1, 1.9.0, 1.9.1rc1, 1.9.1rc2, 1.9.1, 1.9.2rc1, 1.9.2, 1.10.0rc1, 1.10.0rc2, 1.10.0, 1.11.0rc1, 1.11.0, 1.11.1rc1, 1.11.1, 1.12.0rc1, 1.12.0rc2, 1.12.0)\n",
      "ERROR: No matching distribution found for streamlit>=1.31.1\n"
     ]
    }
   ],
   "source": [
    "!pip install trulens-eval==0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c063c9c7-bf1e-4b24-9a22-d4281c0f954e",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trulens_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JULINR~1\\AppData\\Local\\Temp/ipykernel_26716/2801267818.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrulens_eval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtru\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'trulens_eval'"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03802825-6ce4-4563-aeec-d8d57e095ad1",
   "metadata": {},
   "source": [
    "For the classroom, we've written some of the code in helper functions inside a utils.py file.  \n",
    "- You can view the utils.py file in the file directory by clicking on the \"Jupyter\" logo at the top of the notebook.\n",
    "- In later lessons, you'll get to work directly with the code that's currently wrapped inside these helper functions, to give you more options to customize your RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f754bed-d16f-4c8d-a1a1-b36096272570",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdfbcc-aac7-4805-9894-4fc016c66bf6",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f512b-601c-42d0-bfac-bf41d9c577e7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4a602-0d56-4bf8-9fa6-03ef0b7e254b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64310897-179b-4081-aab8-f08a3392a078",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eedcef",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea2b",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4a668-3699-4750-82f7-e53ae1bca3a7",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7678f-358d-448d-b153-11ac8e96a7fc",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f904c3-9845-4df5-9d2e-e5115160f987",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e2314-7cac-42f4-a552-9a8e4db641eb",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"how do I get started on a personal project in AI?\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c10917-8846-4e73-838d-6232c906a7db",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11710e67-aba8-479e-8585-c4c611e2c1d2",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1e55-729b-45f2-a0f9-773c49d4616f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92d0f2-2e80-48d5-92af-b3655eb03ea2",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2c55",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c639b-31eb-4c34-b6c4-fe6ae5717733",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32265f2-0247-42df-9abe-97d52f69edcf",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ed568-220e-4c7c-aa60-cfa58ef1fcbd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f18a9-7b8a-4ae2-ab11-3a6a941a5afc",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerging_query_engine,\n",
    "                                                         app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc2cfe-7096-4fa0-aa72-094bebac35a3",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404dec1-60ca-42fa-ac13-793a5423aa64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f545d41-0d98-446f-8214-8b59bef08d6c",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
